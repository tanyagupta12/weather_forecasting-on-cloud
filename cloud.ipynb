{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanyagupta12/weather_forecasting-on-cloud/blob/main/cloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('/content/Weather Data.csv')\n",
        "\n",
        "# Select features\n",
        "selected_features = ['Temp_C', 'Dew Point Temp_C', 'Rel Hum_%', 'Wind Speed_km/h', 'Visibility_km', 'Press_kPa']\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = MinMaxScaler()\n",
        "numeric_data = data[selected_features]\n",
        "scaled_data = scaler.fit_transform(numeric_data)\n",
        "\n",
        "# Perform one-hot encoding for the \"Weather\" column\n",
        "scaled_data = np.concatenate([scaled_data, pd.get_dummies(data['Weather'])], axis=1)\n",
        "\n",
        "# Define parameters\n",
        "sequence_length = 10  # Length of input sequences\n",
        "n_features = scaled_data.shape[1]  # Number of input features\n",
        "n_units = 50  # Number of units in the LSTM layer\n",
        "\n",
        "# Create sequences\n",
        "sequences = []\n",
        "targets = []\n",
        "for i in range(len(scaled_data) - sequence_length):\n",
        "    sequences.append(scaled_data[i:i+sequence_length])\n",
        "    targets.append(scaled_data[i+sequence_length][0])  # Predicting temperature, so select the first feature\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "sequences = np.array(sequences)\n",
        "targets = np.array(targets)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "split = int(0.8 * len(sequences))\n",
        "X_train, X_test = sequences[:split], sequences[split:]\n",
        "y_train, y_test = targets[:split], targets[split:]\n",
        "\n",
        "# Define the RNN model with increased complexity\n",
        "model = Sequential([\n",
        "    LSTM(n_units, return_sequences=True, input_shape=(sequence_length, n_features)),\n",
        "    LSTM(n_units),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model with a smaller learning rate\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model for more epochs\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "\n",
        "# Create DataFrame for actual and predicted values\n",
        "actual = pd.DataFrame(y_test, columns=['Actual'])\n",
        "predicted = pd.DataFrame(predictions, columns=['Predicted'])\n",
        "\n",
        "# Concatenate actual and predicted values\n",
        "results = pd.concat([actual, predicted], axis=1)\n",
        "print(results.head(40))  # Print the first 20 rows\n",
        "\n",
        "# Round predictions to the nearest integer\n",
        "rounded_predictions = predictions\n",
        "\n",
        "\n",
        "tolerance=0.02\n",
        "# Initialize correct_predictions counter\n",
        "correct_predictions = 0\n",
        "\n",
        "# Iterate through each prediction and actual value\n",
        "for pred, actual in zip(predictions, y_test):\n",
        "    # Check if the absolute difference between prediction and actual is less than or equal to the tolerance\n",
        "    if (pred - actual) <= tolerance:\n",
        "        # If yes, increment correct_predictions by 1\n",
        "        correct_predictions += 1\n",
        "\n",
        "print(correct_predictions)\n",
        "# Calculate total number of predictions\n",
        "total_predictions = len(y_test)\n",
        "print(len(y_test))\n",
        "# Calculate accuracy\n",
        "accuracy = (correct_predictions / total_predictions) * 100\n",
        "\n",
        "print(\"Accuracy:\",accuracy,\"%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucScQ4RbcPMn",
        "outputId": "aa948bae-208c-4aa6-9929-8a82db749803"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "220/220 [==============================] - 8s 20ms/step - loss: 0.0112 - val_loss: 0.0025\n",
            "Epoch 2/10\n",
            "220/220 [==============================] - 3s 15ms/step - loss: 0.0018 - val_loss: 0.0020\n",
            "Epoch 3/10\n",
            "220/220 [==============================] - 3s 13ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 4/10\n",
            "220/220 [==============================] - 3s 13ms/step - loss: 0.0011 - val_loss: 0.0015\n",
            "Epoch 5/10\n",
            "220/220 [==============================] - 3s 15ms/step - loss: 9.9364e-04 - val_loss: 0.0012\n",
            "Epoch 6/10\n",
            "220/220 [==============================] - 3s 15ms/step - loss: 7.8863e-04 - val_loss: 0.0011\n",
            "Epoch 7/10\n",
            "220/220 [==============================] - 3s 14ms/step - loss: 7.2430e-04 - val_loss: 9.3398e-04\n",
            "Epoch 8/10\n",
            "220/220 [==============================] - 3s 13ms/step - loss: 5.8412e-04 - val_loss: 7.6924e-04\n",
            "Epoch 9/10\n",
            "220/220 [==============================] - 3s 14ms/step - loss: 5.1414e-04 - val_loss: 6.7018e-04\n",
            "Epoch 10/10\n",
            "220/220 [==============================] - 4s 16ms/step - loss: 5.1749e-04 - val_loss: 5.8630e-04\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 5.8630e-04\n",
            "Test Loss: 0.0005863018450327218\n",
            "55/55 [==============================] - 1s 5ms/step\n",
            "      Actual  Predicted\n",
            "0   0.658970   0.642281\n",
            "1   0.651865   0.661263\n",
            "2   0.653641   0.650801\n",
            "3   0.648313   0.645809\n",
            "4   0.642984   0.641115\n",
            "5   0.641208   0.643257\n",
            "6   0.641208   0.650984\n",
            "7   0.634103   0.681391\n",
            "8   0.635879   0.675086\n",
            "9   0.602131   0.659734\n",
            "10  0.623446   0.630301\n",
            "11  0.639432   0.620355\n",
            "12  0.658970   0.622187\n",
            "13  0.698046   0.637945\n",
            "14  0.705151   0.686503\n",
            "15  0.735346   0.701252\n",
            "16  0.726465   0.733164\n",
            "17  0.719361   0.750253\n",
            "18  0.705151   0.736362\n",
            "19  0.662522   0.697536\n",
            "20  0.651865   0.648175\n",
            "21  0.632327   0.629114\n",
            "22  0.619893   0.616380\n",
            "23  0.603908   0.598254\n",
            "24  0.609236   0.594307\n",
            "25  0.600355   0.594658\n",
            "26  0.595027   0.592274\n",
            "27  0.577265   0.589598\n",
            "28  0.589698   0.576856\n",
            "29  0.596803   0.572566\n",
            "30  0.602131   0.576808\n",
            "31  0.595027   0.588979\n",
            "32  0.600355   0.591466\n",
            "33  0.593250   0.586780\n",
            "34  0.587922   0.584819\n",
            "35  0.595027   0.578121\n",
            "36  0.598579   0.579341\n",
            "37  0.607460   0.581667\n",
            "38  0.612789   0.586364\n",
            "39  0.637655   0.591420\n",
            "1525\n",
            "1755\n",
            "Accuracy: 86.8945868945869 %\n"
          ]
        }
      ]
    }
  ]
}